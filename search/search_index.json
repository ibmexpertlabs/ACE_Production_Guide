{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ACE Production Guide","text":"<p>Welcome to the App Connect Enterprise (ACE) Production Deployment Guide - your comprehensive resource for deploying enterprise-grade ACE applications on OpenShift Container Platform using modern cloud-native practices.</p>"},{"location":"#what-youll-learn","title":"\ud83d\ude80 What You'll Learn","text":"<p>This guide provides expert-level instructions for building, deploying, and managing ACE applications in production environments using:</p> <ul> <li>IBM Cloud Pak for Integration (CP4I)</li> <li>OpenShift Container Platform</li> <li>GitOps workflows with ArgoCD</li> <li>CI/CD pipelines with Tekton</li> <li>Cloud-native best practices</li> </ul>"},{"location":"#target-audience","title":"\ud83c\udfaf Target Audience","text":"<p>This guide is designed for:</p> <ul> <li>Platform Engineers - Setting up and managing the infrastructure</li> <li>DevOps Engineers - Implementing CI/CD pipelines and automation</li> <li>Integration Developers - Building and deploying ACE applications</li> <li>System Administrators - Managing production environments</li> <li>Solution Architects - Designing enterprise integration solutions</li> </ul>"},{"location":"#whats-covered","title":"\ud83d\udccb What's Covered","text":""},{"location":"#foundation","title":"Foundation","text":"<ul> <li>OpenShift cluster setup and configuration</li> <li>GitOps infrastructure with ArgoCD</li> <li>Security and compliance considerations</li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>ACE application development best practices</li> <li>Containerization and build processes</li> <li>Testing and validation strategies</li> </ul>"},{"location":"#deployment","title":"Deployment","text":"<ul> <li>Production deployment patterns</li> <li>Environment promotion workflows</li> <li>Monitoring and observability</li> </ul>"},{"location":"#operations","title":"Operations","text":"<ul> <li>Troubleshooting and debugging</li> <li>Performance optimization</li> <li>Maintenance and updates</li> </ul>"},{"location":"#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<p>Our production deployment follows a layered GitOps approach:</p> <pre><code>graph TB\n    A[OpenShift Cluster] --&gt; B[Infrastructure Layer]\n    B --&gt; C[Services Layer]\n    C --&gt; D[Applications Layer]\n\n    B --&gt; E[Namespaces]\n    B --&gt; F[Storage]\n    B --&gt; G[Security]\n\n    C --&gt; H[ACE Operator]\n    C --&gt; I[Tekton Pipelines]\n    C --&gt; J[ArgoCD]\n\n    D --&gt; K[ACE Applications]\n    D --&gt; L[Integration Servers]\n    D --&gt; M[Message Flows]</code></pre>"},{"location":"#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Access to an OpenShift 4.16+ cluster</li> <li>IBM Cloud Pak for Integration entitlement</li> <li>Basic knowledge of Kubernetes and OpenShift</li> <li>Familiarity with Git and CI/CD concepts</li> </ul>"},{"location":"#getting-started","title":"\ud83d\udea6 Getting Started","text":"<p>This guide follows a structured approach to deploying ACE in production:</p> <ol> <li>Cluster Setup - Create and configure your OpenShift cluster</li> <li>GitOps Configuration - Set up ArgoCD and repository structure  </li> <li>Infrastructure Deployment - Set up namespaces and resources</li> <li>Service Installation - Deploy ACE operator and supporting services</li> <li>Application Building - Create and deploy your ACE applications</li> </ol>"},{"location":"#repository-structure","title":"\ud83d\udcda Repository Structure","text":"<p>This guide references four key repositories:</p> <ul> <li>multi-tenancy-gitops - Main GitOps orchestration</li> <li>multi-tenancy-gitops-infra - Infrastructure resources</li> <li>multi-tenancy-gitops-services - Service operators and instances</li> <li>multi-tenancy-gitops-apps - ACE applications and configurations</li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>This guide is maintained by IBM Client Engineering. For questions, suggestions, or contributions, please:</p> <ul> <li>Open an issue on our GitHub repository</li> <li>Contact the team through IBM Client Engineering channels</li> <li>Submit pull requests for improvements</li> </ul>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the IBM License Agreement.</p> <p>Ready to get started? Follow the structured approach above to deploy ACE in your production environment. </p>"},{"location":"ace-tutorial/","title":"The ACE Tutorial","text":"<p>Audience: Architects, Application Developers, Administrators</p>"},{"location":"ace-tutorial/#overview","title":"Overview","text":"<p>In this topic, we're going to:</p> <ul> <li>Introduce you to the ACE tutorial</li> <li>Outline the structure of the tutorial</li> <li>Explain the cloud-native approach to ACE deployment</li> </ul> <p>By the end of this topic, you will understand the ACE tutorial and how it can help you design and build cloud-native ACE systems.</p>"},{"location":"ace-tutorial/#introduction","title":"Introduction","text":"<p>IBM Cloud Pak for Integration includes a market-leading application integration capability called App Connect Enterprise (ACE). It enables the implementation of API and event-driven integrations and provides extensive adaptation to on-premises and cloud-based applications. </p> <p>ACE provides tooling that is optimized to users' skillsets, allowing them to be productive in a matter of hours and achieve real results in days. Powerful underlying capabilities facilitate the implementation of even the most complex integration patterns, ensuring data can be moved quickly, accurately, and robustly.</p>"},{"location":"ace-tutorial/#purpose-of-this-guide","title":"Purpose of This Guide","text":"<p>The purpose of this guide is to teach you how to deploy an ACE application on OpenShift Container Platform using modern cloud-native practices. We will be using:</p> <ul> <li>Cloud Pak for Integration (CP4I)</li> <li>Containers and Operators</li> <li>Microservices architecture</li> <li>Immutable infrastructure</li> <li>Declarative APIs</li> </ul> <p>This approach creates a best-practice-based, production-ready deployment of an ACE message flow. You will also learn how technologies such as OpenShift Pipelines (Tekton) and OpenShift GitOps (ArgoCD) integrate in a production environment.</p>"},{"location":"ace-tutorial/#tutorial-structure","title":"Tutorial Structure","text":"<p>This tutorial is divided into chapters that help you build, step-by-step, an ACE integration runtime based on a cloud-native approach. Each chapter comprises topics which you should complete in order to gain a full understanding.</p>"},{"location":"ace-tutorial/#example-integration-flow","title":"Example Integration Flow","text":"<p>The tutorial uses an example integration flow that will: - Communicate with a backend service - Retrieve data from the service - Send back a response to the user</p> <p>This practical example demonstrates real-world integration patterns and best practices.</p>"},{"location":"ace-tutorial/#development-and-operations-lifecycle","title":"Development and Operations Lifecycle","text":"<p>The tutorial is structured to match the modern development and operations lifecycle:</p> <ol> <li>Install and Upgrade - Setting up the foundation</li> <li>Build and Test - Creating and validating your integration</li> <li>Deployment - Getting your application into production</li> <li>Promotion - Managing environments and releases</li> </ol> <p>This lifecycle approach ensures you understand not just how to build ACE applications, but how to operate them effectively in production environments.</p>"},{"location":"ace-tutorial/#what-youll-learn","title":"What You'll Learn","text":"<p>Throughout this tutorial, you'll gain hands-on experience with:</p> <ul> <li>OpenShift Container Platform fundamentals</li> <li>GitOps workflows with ArgoCD</li> <li>CI/CD pipelines with Tekton</li> <li>ACE application development and deployment</li> <li>Production best practices for enterprise integration</li> <li>Monitoring and observability for ACE applications</li> </ul>"},{"location":"ace-tutorial/#prerequisites","title":"Prerequisites","text":"<p>Before starting this tutorial, ensure you have:</p> <ul> <li>Basic understanding of Kubernetes concepts</li> <li>Familiarity with container technologies</li> <li>Knowledge of integration patterns and APIs</li> <li>Access to an OpenShift 4.16+ cluster</li> <li>IBM Cloud Pak for Integration entitlement</li> </ul> <p>Ready to begin? Follow the tutorial chapters in order to build your first cloud-native ACE application. </p>"},{"location":"authors/","title":"Meet the Authors","text":""},{"location":"authors/#alejandro-palumbo","title":"Alejandro Palumbo","text":"<p>IBM Platform Engineer - IBM Client Engineering</p> <ul> <li>LinkedIn: Alejandro Palumbo</li> <li>GitHub: [@apalumbo-ibm](https://github.com/asapalejandro</li> </ul>"},{"location":"authors/#ibm-summer-interns-for-platform-engineering","title":"IBM Summer Interns for Platform Engineering","text":""},{"location":"authors/#james-foxworth","title":"James Foxworth","text":"<p>Rice University - Expected graduation: May 2026</p> <ul> <li>LinkedIn: James Foxworth</li> <li>GitHub: @jamesfoxworth</li> <li>Fun fact: Likes coffee</li> </ul>"},{"location":"authors/#princeobiuto-aguguo","title":"Princeobiuto Aguguo","text":"<ul> <li>LinkedIn: Princeobiuto Aguguo</li> <li>GitHub: @agugoat</li> <li>Fun facts: </li> <li>Likes turtles (diamondback terrapin)</li> <li>Has 4 siblings</li> <li>Thinks Steph Curry &gt; LeBron James </li> </ul>"},{"location":"configure-cluster-gitops/","title":"Configure the Cluster for GitOps","text":"<p>Audience: Architects, Application Developers, Administrators</p>"},{"location":"configure-cluster-gitops/#overview","title":"Overview","text":"<p>In this topic, you will:</p> <ul> <li>Create a GitHub organization for GitOps repositories</li> <li>Clone and review sample GitOps repositories</li> <li>Install and configure ArgoCD for continuous deployment</li> <li>Set up custom ArgoCD instance with IBM Cloud Pak health checks</li> <li>Access and configure the ArgoCD web console</li> </ul> <p>By the end of this topic, you'll have all the basic components in place to perform GitOps in your cluster.</p>"},{"location":"configure-cluster-gitops/#introduction","title":"Introduction","text":"<p>Continuous integration and continuous deployment (CI/CD) are at the core of a typical ACE deployment. They ensure that any changes to source applications and configurations are automatically built and tested before they are deployed, helping to ensure their correctness and the integrity of the cluster.</p> <p>ACE applications are defined, configured, and changed using a GitOps model. GitOps puts git repositories and git commands such as <code>git push</code> (to request a change) and <code>git merge</code> (to approve a change) at the heart of configuration management. A GitOps approach helps an organization implement best practices in version control and release governance based on a widely used open standard \u2014 git.</p>"},{"location":"configure-cluster-gitops/#gitops-architecture-overview","title":"GitOps Architecture Overview","text":"<p>The following diagram outlines the major components in a GitOps ACE CI/CD process:</p> <p></p> <p>Notice the clear separation of concerns:</p> <ul> <li> <p>Tekton pipelines (OpenShift Pipelines) use Integration Application (message flows, ESQL, mapping, etc.) and configurations (serverconf, policy projects) source repositories to build and store successfully tested Kubernetes artifacts in a Git config repository or image registry. While Kubernetes resources (e.g., pods, routes...) can be created as part of the pipeline run to test the source change, these resources only last for the duration of the pipeline run. It is the resultant Git and container image registry resources that are used to affect changes to the cluster in a subsequent, asynchronous processing step controlled by ArgoCD.</p> </li> <li> <p>ArgoCD applications (OpenShift GitOps) watch a Git config repository for changes built as a result of successful pipeline runs. This repository identifies the latest version of the application using information stored in Git and an image repository. OpenShift GitOps applies the Kubernetes resources thus identified to the cluster, resulting in new or updated Kubernetes resources that represent the changed ACE workflow applications and Integration Servers and its ecosystem, such as pods, routes, etc. In contrast to pipeline runs, OpenShift GitOps changes are durable; they remain as defined unless and until they are explicitly changed or deleted in the GitOps repository. Moreover, if the cluster resources drift from their Git config values, ArgoCD will restore them to their desired values; only changes that are applied to the Git config repository affect the long-term state of the cluster.</p> </li> </ul> <p>OpenShift Pipelines and OpenShift GitOps are used to separate Continuous Integration from Continuous Deployment. Often, the Tekton pipeline will perform its changes under a pull-request (PR) to provide an explicit approval mechanism for cluster changes. This is especially important in higher environments such as production which require a formal sign-off. Lower environments such as development often apply successful pipeline runs directly to the Git config repository that are immediately seen by ArgoCD and applied to the cluster.</p>"},{"location":"configure-cluster-gitops/#prerequisites","title":"Prerequisites","text":"<p>Before attempting this section, you must have completed the following tasks:</p> <ul> <li>\u2705 Created an OCP cluster instance</li> <li>\u2705 Installed the <code>oc</code> command that matches your cluster version (4.19+ client, 4.16+ server)</li> <li>\u2705 Installed <code>npm</code>, <code>git</code>, <code>tree</code>, and <code>jq</code> commands</li> <li>\u2705 Have cluster administrator access</li> </ul> <p>OpenShift CLI Installation</p> <p>Use these instructions to get the latest version of <code>oc</code>. Use <code>oc version</code> to confirm that you have: - Client Version: 4.19 or higher - Server Version: 4.16 or higher</p>"},{"location":"configure-cluster-gitops/#setting-up-github-organization","title":"Setting up GitHub Organization","text":"<p>In this section, we'll create the GitOps organization that contains the GitOps repositories used by ArgoCD to determine the state of our cluster. We'll copy a set of sample GitOps repositories as a starting point, make our own copy, and review its contents. Later in the tutorial, we'll customize it for our cluster.</p>"},{"location":"configure-cluster-gitops/#1-create-a-new-github-organization","title":"1. Create a New GitHub Organization","text":"<p>We're going to create a dedicated GitHub organization for the repositories used in this tutorial. This is good practice as it allows you to keep your production reference work separate from other git work, or try out multiple configurations using different organizations.</p> <ol> <li> <p>In your browser, navigate to GitHub Organizations to create a new GitHub organization.</p> </li> <li> <p>Click \"New organization\" and follow the setup process:</p> </li> </ol> <p></p> <ol> <li> <p>Choose a descriptive name for your organization (e.g., <code>ace-production-gitops</code>)</p> </li> <li> <p>Select the Free plan (sufficient for this tutorial)</p> </li> <li> <p>Complete the organization setup</p> </li> </ol>"},{"location":"configure-cluster-gitops/#2-set-up-repository-access","title":"2. Set Up Repository Access","text":"<p>Once your organization is created, you'll need to set up proper access for ArgoCD to read your repositories:</p> <ol> <li>Navigate to your organization settings</li> <li>Go to Developer settings \u2192 Personal access tokens \u2192 Tokens (classic)</li> <li>Generate a new token with the following permissions:</li> <li><code>repo</code> (Full control of private repositories)</li> <li> <p><code>read:org</code> (Read organization data)</p> </li> <li> <p>Save the token securely - you'll need it for ArgoCD configuration</p> </li> </ol>"},{"location":"configure-cluster-gitops/#clone-sample-gitops-repositories","title":"Clone Sample GitOps Repositories","text":"<p>The GitOps approach uses multiple repositories to manage different aspects of the deployment:</p>"},{"location":"configure-cluster-gitops/#repository-structure","title":"Repository Structure","text":"<ul> <li>multi-tenancy-gitops - Main GitOps orchestration repository</li> <li>multi-tenancy-gitops-infra - Infrastructure resources (namespaces, RBAC, etc.)</li> <li>multi-tenancy-gitops-services - Service operators and instances</li> <li>multi-tenancy-gitops-apps - ACE applications and configurations</li> </ul>"},{"location":"configure-cluster-gitops/#clone-the-repositories","title":"Clone the Repositories","text":"<pre><code># Clone the main GitOps repository\ngit clone https://github.com/ibmexpertlabs/multi-tenancy-gitops.git\ncd multi-tenancy-gitops\n\n# Clone the supporting repositories\ngit clone https://github.com/ibmexpertlabs/multi-tenancy-gitops-infra.git\ngit clone https://github.com/ibmexpertlabs/multi-tenancy-gitops-services.git\ngit clone https://github.com/ibmexpertlabs/multi-tenancy-gitops-apps.git\n</code></pre>"},{"location":"configure-cluster-gitops/#review-repository-structure","title":"Review Repository Structure","text":"<p>Take a moment to explore the repository structure:</p> <pre><code># View the main repository structure\ntree multi-tenancy-gitops -L 2\n\n# Review the ArgoCD applications\nls multi-tenancy-gitops/0-bootstrap/single-cluster/1-infrastructure/\n</code></pre>"},{"location":"configure-cluster-gitops/#installing-argocd","title":"Installing ArgoCD","text":"<p>ArgoCD is the GitOps continuous delivery tool that will manage our cluster state based on Git repository contents.</p>"},{"location":"configure-cluster-gitops/#1-install-argocd-operator","title":"1. Install ArgoCD Operator","text":"<p>ArgoCD is installed via the OpenShift GitOps operator. The installation process creates:</p> <ul> <li>ArgoCD operator subscription</li> <li>Default ArgoCD instance</li> <li>Required cluster roles and bindings</li> </ul> <pre><code># Apply the ArgoCD installation manifests\noc apply -f setup/ocp4x/argocd-operator/ -n openshift-operators\n</code></pre>"},{"location":"configure-cluster-gitops/#2-verify-installation","title":"2. Verify Installation","text":"<p>Monitor the installation progress:</p> <pre><code># Wait for the ArgoCD operator to be installed\nwhile ! oc wait crd applications.argoproj.io --timeout=-1s --for=condition=Established 2&gt;/dev/null; do \n    echo \"Waiting for ArgoCD operator...\"\n    sleep 30\ndone\n\n# Wait for ArgoCD pods to be ready\nwhile ! oc wait pod --timeout=-1s --for=condition=Ready --all -n openshift-gitops 2&gt;/dev/null; do \n    echo \"Waiting for ArgoCD pods...\"\n    sleep 30\ndone\n</code></pre> <p>You should see: <pre><code>customresourcedefinition.apiextensions.k8s.io/applications.argoproj.io condition met\n</code></pre></p>"},{"location":"configure-cluster-gitops/#3-verify-cluster-roles","title":"3. Verify Cluster Roles","text":"<p>ArgoCD runs under a dedicated service account with custom cluster roles for governance:</p> <pre><code># Verify cluster roles are created\noc get clusterrole custom-argocd-cluster-argocd-application-controller\noc get clusterrolebinding openshift-gitops-argocd-application-controller\noc get clusterrolebinding openshift-gitops-cntk-argocd-application-controller\n</code></pre>"},{"location":"configure-cluster-gitops/#4-remove-default-instance","title":"4. Remove Default Instance","text":"<p>The default ArgoCD instance isn't sufficient for our tutorial. We need to create a custom one:</p> <pre><code># Delete the default ArgoCD instance\noc delete gitopsservice cluster || true\n</code></pre>"},{"location":"configure-cluster-gitops/#creating-a-custom-argocd-instance","title":"Creating a Custom ArgoCD Instance","text":"<p>The default instance of ArgoCD provides built-in health checks for standard Kubernetes resources. However, these checks are not sufficient for the custom resources added by IBM Cloud Paks. We need to create a custom instance with IBM Cloud Pak-specific health checks.</p>"},{"location":"configure-cluster-gitops/#1-review-custom-health-checks","title":"1. Review Custom Health Checks","text":"<p>Explore the custom health checks in the ArgoCD YAML:</p> <pre><code>cat setup/ocp4x/argocd-instance/argocd-instance.yaml\n</code></pre> <p>Notice the custom health check for queue managers:</p> <pre><code>mq.ibm.com/QueueManager:\n  health.lua: |\n    hs = {}\n    if obj.status ~= nil then\n      if obj.status.phase ~= nil then\n        hs.message = obj.status.phase\n        if obj.status.phase == \"Running\" then\n          hs.status = \"Healthy\"\n        else\n          hs.status = \"Progressing\"\n        end\n        return hs\n      end\n    end\n    hs.status = \"Progressing\"\n    hs.message = \"Unknown\"\n    return hs\n</code></pre> <p>This logic is used by ArgoCD to determine when a queue manager is healthy.</p> <p>Custom Health Checks</p> <p>The custom ArgoCD instance includes IBM Cloud Pak-specific health checks for: - Queue Managers (<code>mq.ibm.com/QueueManager</code>) - Integration Servers (<code>appconnect.ibm.com/IntegrationServer</code>) - ACE Applications (<code>appconnect.ibm.com/Application</code>) - Other Cloud Pak resources</p> <p>These health checks ensure ArgoCD can properly monitor the status of IBM Cloud Pak resources and provide accurate health assessments in the ArgoCD dashboard.</p>"},{"location":"configure-cluster-gitops/#2-create-custom-argocd-instance","title":"2. Create Custom ArgoCD Instance","text":"<pre><code># Create the custom ArgoCD instance\noc apply -f setup/ocp4x/argocd-instance/ -n openshift-gitops\n</code></pre> <p>You should see: <pre><code>argocd.argoproj.io/openshift-gitops-cntk created\n</code></pre></p>"},{"location":"configure-cluster-gitops/#3-wait-for-instance-to-be-ready","title":"3. Wait for Instance to be Ready","text":"<pre><code># Wait for ArgoCD instance to be ready\nwhile ! oc wait pod --timeout=-1s --for=condition=ContainersReady -l app.kubernetes.io/name=openshift-gitops-cntk-server -n openshift-gitops &gt; /dev/null; do \n    echo \"Waiting for ArgoCD instance...\"\n    sleep 30\ndone\n</code></pre> <p>Installation Timing</p> <p>The custom ArgoCD instance installation is an asynchronous process. The operator installation takes time, and once the operator is installed, the custom ArgoCD instance also takes time to create. The wait commands ensure all components are fully ready before proceeding.</p>"},{"location":"configure-cluster-gitops/#4-configure-ssl-certificate-optional","title":"4. Configure SSL Certificate (Optional)","text":"<p>Firefox Browser Users</p> <p>If you are using Firefox, you will not be able to access the ArgoCD console until a valid certificate has been associated with it. Other browsers are unaffected.</p> <pre><code># Create temporary directory\nmkdir /tmp/argocd-cert\ncd /tmp/argocd-cert\n\n# Extract the ingress certificate\ningress_secret_name=$(oc get ingresscontroller.operator default \\\n  --namespace openshift-ingress-operator \\\n  -o jsonpath='{.spec.defaultCertificate.name}')\n\noc extract secret/$ingress_secret_name -n openshift-ingress\n\n# Create TLS secret for ArgoCD\noc create secret tls -n openshift-gitops openshift-gitops-cntk-tls \\\n  --cert=tls.crt --key=tls.key --dry-run=client -o yaml | oc apply -f -\n\n# Clean up\ncd ..\nrm -rf /tmp/argocd-cert\n</code></pre>"},{"location":"configure-cluster-gitops/#accessing-argocd","title":"Accessing ArgoCD","text":""},{"location":"configure-cluster-gitops/#1-get-argocd-url","title":"1. Get ArgoCD URL","text":"<p>ArgoCD can be accessed via an OpenShift route:</p> <pre><code># Get the ArgoCD route URL\noc get route openshift-gitops-cntk-server -n openshift-gitops -o jsonpath='{\"https://\"}{.spec.host}{\"\\n\"}'\n</code></pre> <p>Example output: <pre><code>https://openshift-gitops-cntk-server-openshift-gitops.apps.itz-pokxlu.hub01-lb.techzone.ibm.com\n</code></pre></p>"},{"location":"configure-cluster-gitops/#2-access-argocd-console","title":"2. Access ArgoCD Console","text":"<ol> <li>Copy the URL from your terminal output into your browser</li> <li>You should see the ArgoCD login page:</li> </ol> <p>Certificate Warnings</p> <p>You can safely ignore any browser certificate warnings.</p>"},{"location":"configure-cluster-gitops/#3-authentication-options","title":"3. Authentication Options","text":"<p>ArgoCD provides two authentication mechanisms:</p>"},{"location":"configure-cluster-gitops/#option-1-argocd-administrator-recommended","title":"Option 1: ArgoCD Administrator (Recommended)","text":"<p>Use the ArgoCD service account credentials for full administrative access:</p> <ul> <li>Username: <code>admin</code></li> <li>Password: Retrieve using the following command:</li> </ul> <pre><code>oc extract secret/openshift-gitops-cntk-cluster -n openshift-gitops --keys=\"admin.password\" --to=-\n</code></pre>"},{"location":"configure-cluster-gitops/#option-2-openshift-sso","title":"Option 2: OpenShift SSO","text":"<p>Use your OpenShift Single Sign-On credentials:</p> <ol> <li>Click \"Login with OpenShift\"</li> <li>Grant access to the ArgoCD Service Account when prompted:</li> </ol> <p></p> <p>Permission Differences</p> <p>OpenShift SSO authentication provides sufficient permissions to complete the tutorial, but you won't have full administrative access to perform all ArgoCD operations.</p>"},{"location":"configure-cluster-gitops/#4-argocd-dashboard","title":"4. ArgoCD Dashboard","text":"<p>Once logged in, you'll see the ArgoCD dashboard:</p> <p></p> <p>Notice that there are no ArgoCD applications active at the moment. In the next section, we'll configure ArgoCD to create the ArgoCD applications that will spin up infrastructure, service, and application resources.</p>"},{"location":"configure-cluster-gitops/#next-steps","title":"Next Steps","text":"<p>With ArgoCD installed and configured, you're ready to:</p> <ol> <li>Configure Git Repository Access - Set up ArgoCD to read your GitOps repositories</li> <li>Create ArgoCD Applications - Define applications for infrastructure, services, and ACE components</li> <li>Deploy Infrastructure - Set up namespaces, RBAC, and foundational resources</li> <li>Install Cloud Pak for Integration - Deploy CP4I with GitOps automation</li> </ol> <p>Congratulations!</p> <p>You have successfully created the GitOps repository for your cluster and examined its high-level structure. You also installed ArgoCD with a custom instance that includes IBM Cloud Pak-specific health checks. You created specific clusterrole and clusterrolebinding for the ArgoCD service account to ensure that it manages the cluster in a well-governed manner. Finally, you launched the UI for ArgoCD; you will make extensive use of it during this tutorial.</p> <p>In the next topic of this chapter, we are going to customize the GitOps repository for your cluster and use Tekton and ArgoCD to create and manage the Kubernetes resources for our ACE applications.</p>"},{"location":"configure-cluster-gitops/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configure-cluster-gitops/#common-issues","title":"Common Issues","text":"<p>ArgoCD Installation Delays - Check operator subscription status: <code>oc get subscription -n openshift-operators</code> - Verify operator pod status: <code>oc get pods -n openshift-operators</code> - Check ArgoCD namespace: <code>oc get pods -n openshift-gitops</code></p> <p>Authentication Issues - Verify the admin password extraction command - Check OpenShift SSO configuration - Ensure proper cluster permissions</p> <p>Route Access Problems - Verify the route exists: <code>oc get route -n openshift-gitops</code> - Check certificate configuration for Firefox users - Ensure network connectivity to the cluster</p>"},{"location":"configure-cluster-gitops/#support-resources","title":"Support Resources","text":"<ul> <li>ArgoCD Documentation</li> <li>OpenShift GitOps Documentation</li> <li>IBM Cloud Pak for Integration Documentation</li> <li>Production GitOps Guide - Comprehensive GitOps setup guide</li> <li>ArgoCD Resource Health - Custom health check documentation</li> <li>Lua Programming Language - For custom health check development</li> </ul> <p>Next Steps: Once ArgoCD is configured, proceed to Add Infrastructure to set up the foundational resources for your ACE deployment. </p>"},{"location":"create-cluster/","title":"Create the Cluster","text":"<p>Audience: Architects, Application Developers, Administrators</p>"},{"location":"create-cluster/#overview","title":"Overview","text":"<p>In this topic, you will:</p> <ul> <li>Learn how to provision an OpenShift cluster on IBM Cloud</li> <li>Understand the cluster reservation process</li> <li>Configure cluster specifications for ACE workloads</li> <li>Monitor cluster provisioning status</li> </ul> <p>By the end, you'll have a production-ready OpenShift cluster configured for App Connect Enterprise deployment.</p>"},{"location":"create-cluster/#prerequisites","title":"Prerequisites","text":"<p>Before creating your cluster, ensure you have:</p> <ul> <li>IBM Technology Zone account access</li> <li>Valid IBM credentials</li> <li>Understanding of your cluster requirements</li> <li>Network access to IBM Cloud services</li> </ul>"},{"location":"create-cluster/#cluster-creation-process","title":"Cluster Creation Process","text":""},{"location":"create-cluster/#1-navigate-to-ibm-technology-zone","title":"1. Navigate to IBM Technology Zone","text":"<ol> <li>In your browser, go to IBM Technology Zone \u2192 Create Reservation</li> <li>If you're not signed in, authenticate with your IBM credentials</li> <li>Read and accept Terms and Conditions if prompted</li> </ol>"},{"location":"create-cluster/#2-reserve-a-cluster","title":"2. Reserve a Cluster","text":"<p>On the Environment Catalog page, select OpenShift Cluster (OCP-v) \u2013 IBM Cloud and click Reserve environment.</p> <p></p>"},{"location":"create-cluster/#3-complete-the-reservation-form","title":"3. Complete the Reservation Form","text":""},{"location":"create-cluster/#step-1-basic-details","title":"Step 1: Basic Details","text":"<p>Fill out the top section:</p> <ul> <li>Cluster Name - Choose a descriptive name for your cluster</li> <li>Purpose - Select from the available options</li> <li>Description - Required if you choose \"Practice/Self-Education\"</li> <li>Sales Opportunity Number - Include if you have one</li> </ul> <p></p>"},{"location":"create-cluster/#step-2-advanced-options","title":"Step 2: Advanced Options","text":"<p>Scroll down and configure the cluster specifications:</p> <ul> <li>Preferred Geography - Choose your preferred region (e.g., <code>London 5</code>, <code>HongKong 2</code>, <code>San Jose 04</code>)</li> <li>End Date &amp; Time - Adjust default 3-day retention if needed</li> <li>Worker Node Count: <code>3</code> (recommended for production workloads)</li> <li>Worker Node Flavor: <code>4 vCPU x 16GB 100GB</code> (minimum for ACE workloads)</li> </ul> <p>Tip</p> <p>Keeping the default 3-day window is usually sufficient. GitOps makes reprovisioning quick if you need another environment.</p> <p>Important Notes</p> <ul> <li>Provisioning takes 3\u20135 hours</li> <li>By default, your cluster auto-deletes after 2 days</li> <li>Use Schedule for later if you plan to reserve it for a future demo or session</li> </ul>"},{"location":"create-cluster/#4-watch-for-email-notifications","title":"4. Watch for Email Notifications","text":"<p>You'll receive several email notifications during the provisioning process:</p> <ul> <li>Provisioning Started - Build process has begun</li> <li>Cluster Ready - Includes your cluster URL and expiry information</li> <li>Daily Notice - When 3 days remain until auto-deletion</li> </ul> <p>To extend your cluster, visit My reservations \u2192 Extend.</p>"},{"location":"create-cluster/#5-track-status-in-ibm-technology-zone","title":"5. Track Status in IBM Technology Zone","text":"<ol> <li>Go to My reservations</li> <li>Monitor the Status column</li> <li>When it reads Ready, your cluster is live and accessible</li> </ol>"},{"location":"create-cluster/#6-access-your-cluster","title":"6. Access Your Cluster","text":"<p>Once ready, click the Cluster URL to open the OpenShift Console and begin navigating your new cluster.</p> <p></p>"},{"location":"create-cluster/#cluster-specifications","title":"Cluster Specifications","text":""},{"location":"create-cluster/#minimum-system-requirements","title":"Minimum System Requirements","text":"<p>For Cloud Pak for Integration 16.1.2, ensure your cluster meets these minimum requirements:</p> Component Minimum Specification Notes OpenShift Version 4.16+ Latest stable release with full CP4I support Worker Nodes 3 Required for high availability deployment Node Flavor 4 vCPU x 16GB Minimum for CP4I foundational services Storage Block RWO storage class Required for Cloud Pak foundational services"},{"location":"create-cluster/#storage-requirements-for-high-availability","title":"Storage Requirements for High Availability","text":"<p>Cloud Pak for Integration requires specific storage configurations for high availability deployments:</p>"},{"location":"create-cluster/#cloud-pak-foundational-services","title":"Cloud Pak Foundational Services","text":"<ul> <li>Storage Type: Block RWO</li> <li>Volumes Required: 2 volumes (HA configuration)</li> <li>Purpose: Cloud Native PostgreSQL replicas for Keycloak</li> </ul>"},{"location":"create-cluster/#app-connect-enterprise-components","title":"App Connect Enterprise Components","text":"<ul> <li>Integration Runtime: No persistent storage required</li> <li>Integration Dashboard: File RWX or S3 object storage (minimum 1 IOPS/GB)</li> <li>Integration Design: Block RWO, RWX, or S3 storage</li> <li>Non-HA: 1 volume</li> <li>HA: 3 volumes (one per CouchDB replica)</li> </ul>"},{"location":"create-cluster/#additional-cp4i-services-if-deployed","title":"Additional CP4I Services (if deployed)","text":"<ul> <li>API Connect: 40 volumes (HA configuration)</li> <li>Event Manager: Block RWO storage</li> <li>Kafka Cluster: 6 volumes (HA: 3 broker + 3 ZooKeeper)</li> <li>Messaging Server: 3 volumes (HA configuration)</li> </ul> <p>Storage Class Configuration</p> <p>The installation process automatically selects the default storage class for your cluster.  Ensure your OpenShift administrator has configured a default storage class that meets  the Block RWO requirements for Cloud Pak foundational services.</p>"},{"location":"create-cluster/#resource-allocation-guidelines","title":"Resource Allocation Guidelines","text":"<p>For production environments, consider these resource allocations:</p> <ul> <li>CPU: Allocate based on expected workload (typically 0.5-2 cores per integration runtime)</li> <li>Memory: 512MB-2GB per integration runtime</li> <li>Network: Standard cluster networking with proper ingress/egress configuration</li> </ul>"},{"location":"create-cluster/#post-provisioning-steps","title":"Post-Provisioning Steps","text":"<p>Once your cluster is ready, you'll need to:</p> <ol> <li>Verify Storage Configuration - Ensure Block RWO storage class is properly configured</li> <li>Configure GitOps - Set up ArgoCD for continuous deployment and high availability</li> <li>Install Cloud Pak for Integration - Deploy CP4I with high availability configuration</li> <li>Configure ACE Services - Set up App Connect Enterprise with HA deployment</li> <li>Set up Monitoring - Configure logging and metrics collection for production monitoring</li> </ol>"},{"location":"create-cluster/#troubleshooting","title":"Troubleshooting","text":""},{"location":"create-cluster/#common-issues","title":"Common Issues","text":"<p>Cluster Provisioning Delays - Check IBM Technology Zone status page - Verify your reservation details - Contact support if delays exceed 6 hours</p> <p>Access Issues - Verify your IBM credentials - Check network connectivity - Ensure you're using the correct cluster URL</p> <p>Resource Limitations - Monitor cluster resource usage - Scale worker nodes if needed - Optimize ACE application resource requests</p>"},{"location":"create-cluster/#support-resources","title":"Support Resources","text":"<ul> <li>IBM Technology Zone Documentation</li> <li>OpenShift Documentation</li> <li>Cloud Pak for Integration 16.1.2 Documentation</li> <li>System Requirements for CP4I</li> <li>ACE Operator Documentation</li> </ul> <p>Next Steps: Once your cluster is ready, proceed to Configure the Cluster to set up GitOps and prepare for ACE deployment. </p>"},{"location":"target-architecture/","title":"Target Architecture","text":"<p>Audience: Architects, Integration Developers, Integration Administrators, Site Reliability Engineers</p>"},{"location":"target-architecture/#overview","title":"Overview","text":"<p>In this topic, you will:</p> <ul> <li>Examine a high-level production deployment for ACE</li> <li>Review the Kubernetes runtime components</li> <li>Understand the GitOps model for ACE configuration and management</li> <li>Identify key users of an ACE deployment</li> </ul> <p>By the end, you'll recognize the major components needed for a production-ready, cloud-native App Connect Enterprise deployment.</p>"},{"location":"target-architecture/#architecture-overview-diagram","title":"Architecture Overview Diagram","text":"<p>The following diagram illustrates a typical ACE production deployment:</p> <p></p>"},{"location":"target-architecture/#key-components","title":"Key Components","text":""},{"location":"target-architecture/#kubernetes-cluster","title":"Kubernetes Cluster","text":"<p>The Kubernetes cluster houses:</p> <ul> <li>ACE Applications - Your integration services and message flows</li> <li>Cloud-Native Tooling - Tekton, ArgoCD, Kibana, Grafana</li> <li>Operators - ACE Operator, Tekton Operator, ArgoCD Operator</li> <li>Infrastructure - Storage, networking, security components</li> </ul>"},{"location":"target-architecture/#github-repositories","title":"GitHub Repositories","text":"<p>GitHub repositories serve as the single source of truth for runtime configuration, containing:</p> <ul> <li>ACE Application Source - One repository per application</li> <li>ACE Shared Library Source - One repository per library</li> <li>Application Configuration Artifacts - Environment-specific configurations</li> <li>CI/CD Definitions - Tekton tasks and pipelines</li> <li>GitOps Manifests - ArgoCD application definitions</li> </ul> <p>This Git-centric approach follows the GitOps model for declarative configuration and management of ACE on Kubernetes.</p>"},{"location":"target-architecture/#users-roles","title":"Users &amp; Roles","text":"<p>A variety of stakeholders interact with the ACE architecture:</p>"},{"location":"target-architecture/#development-team","title":"Development Team","text":"<ul> <li>Integration Developers - Building and testing message flows</li> <li>Application Developers - Creating APIs and services</li> <li>DevOps Engineers - Managing CI/CD pipelines and automation</li> </ul>"},{"location":"target-architecture/#operations-team","title":"Operations Team","text":"<ul> <li>Integration Administrators - Managing deployments and configurations</li> <li>Site Reliability Engineers - Operating infrastructure and monitoring</li> <li>Platform Engineers - Managing the Kubernetes platform</li> </ul>"},{"location":"target-architecture/#business-team","title":"Business Team","text":"<ul> <li>Architects - Defining solution designs and patterns</li> <li>Business Analysts - Specifying integration requirements</li> <li>Product Owners - Prioritizing features and requirements</li> </ul>"},{"location":"target-architecture/#end-users","title":"End Users","text":"<ul> <li>ACE Application Users - Consuming the deployed services</li> <li>API Consumers - Using the exposed APIs</li> <li>System Integrators - Connecting to the integration platform</li> </ul>"},{"location":"target-architecture/#gitops-model","title":"GitOps Model","text":"<p>The architecture follows GitOps principles:</p>"},{"location":"target-architecture/#declarative-configuration","title":"Declarative Configuration","text":"<ul> <li>All configurations are stored in Git</li> <li>Infrastructure is defined as code</li> <li>Changes are version-controlled and auditable</li> </ul>"},{"location":"target-architecture/#continuous-deployment","title":"Continuous Deployment","text":"<ul> <li>ArgoCD monitors Git repositories for changes</li> <li>Automatic deployment when changes are detected</li> <li>Rollback capabilities through Git history</li> </ul>"},{"location":"target-architecture/#separation-of-concerns","title":"Separation of Concerns","text":"<ul> <li>Application code in source repositories</li> <li>Configuration in GitOps repositories</li> <li>Infrastructure managed through operators</li> </ul>"},{"location":"target-architecture/#production-considerations","title":"Production Considerations","text":""},{"location":"target-architecture/#high-availability","title":"High Availability","text":"<ul> <li>Multi-zone deployment across availability zones</li> <li>Replica sets for application redundancy</li> <li>Load balancing and health checks</li> </ul>"},{"location":"target-architecture/#security","title":"Security","text":"<ul> <li>Network policies and security contexts</li> <li>Secrets management with external vaults</li> <li>RBAC and service accounts</li> <li>Image scanning and vulnerability management</li> </ul>"},{"location":"target-architecture/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>Centralized logging with ELK stack</li> <li>Metrics collection with Prometheus</li> <li>Distributed tracing with Jaeger</li> <li>Alerting and incident management</li> </ul>"},{"location":"target-architecture/#scalability","title":"Scalability","text":"<ul> <li>Horizontal pod autoscaling</li> <li>Resource quotas and limits</li> <li>Cluster autoscaling for infrastructure</li> </ul>"},{"location":"target-architecture/#technology-stack","title":"Technology Stack","text":""},{"location":"target-architecture/#core-platform","title":"Core Platform","text":"<ul> <li>OpenShift Container Platform - Enterprise Kubernetes</li> <li>IBM Cloud Pak for Integration - Integration platform</li> <li>App Connect Enterprise - Integration runtime</li> </ul>"},{"location":"target-architecture/#cicd-gitops","title":"CI/CD &amp; GitOps","text":"<ul> <li>Tekton - Cloud-native CI/CD pipelines</li> <li>ArgoCD - GitOps continuous delivery</li> <li>GitHub - Source code and configuration management</li> </ul>"},{"location":"target-architecture/#monitoring-observability_1","title":"Monitoring &amp; Observability","text":"<ul> <li>Prometheus - Metrics collection</li> <li>Grafana - Visualization and dashboards</li> <li>Kibana - Log analysis</li> <li>Jaeger - Distributed tracing</li> </ul>"},{"location":"target-architecture/#security-compliance","title":"Security &amp; Compliance","text":"<ul> <li>OpenShift Security Context Constraints</li> <li>Network Policies - Pod-to-pod communication</li> <li>Secrets Management - External vault integration</li> </ul> <p>Next Steps: This architecture provides the foundation for building production-ready ACE applications. The following chapters will guide you through implementing each component step by step. </p>"}]}